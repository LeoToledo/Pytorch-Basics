{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Um dos processos que mais tomam tempo é a estruturação do dataset.\n",
    "\n",
    "#### Aqui, utilizaremos um dataset já presente no pytorch, que é o Mnist. Posteriormente, faremos a estruturação do nosso próprio dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criaremos um tensor para guardar dados de treino e outro para dados de teste. \n",
    "\n",
    "O método dataset.MNIST irá importar o dataset. O parâmetro transform utiliza métodos da biblioteca transform para fazer as transformações necessárias. Aqui, a única transformação que será feita será a de transformar os dados importados para o tipo Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train = True, download=True, \n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train = False, download=True, \n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: \n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n",
      "Test:  Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: \n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", train)\n",
    "print(\"Test: \", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agora que temos os dados brutos extraídos, vamos tratá-los um pouco.\n",
    "\n",
    "Através do método torch.utils.data.DataLoader, podemos estruturar melhor os dados. Definindo batch_size, estaremos definindo o tamanho dos batches que serão enviados para treinamento por vez na nossa rede neural. Definindo shuffle=True, estaremos embaralhando os dados, evitando vieses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos visualizar um batch do trainset. Nele, veremos 10 matrizes de 28x28 pixels. Cada matriz corresponde a um número. Será mostrado também um tensor com a correspondência de cada matriz. Ex: Se a primeira matriz corresponder a um 2, será apresentado um 2 na primeira posição do Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([8, 4, 8, 4, 8, 7, 9, 6, 5, 1])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos ver como um único exemplo desse batch se parece.\n",
    "\n",
    "obs: A variável data é um tensor. A primeira posição de data corresponde a um Tensor de features ou labels(entradas e saídas). A segunda posição de data corresponde ao número do elemento dentro do batch.\n",
    "\n",
    "Exemplo: <li> data[0] corresponde a 10 Tensors que contém as imagens de entrada. </li> \n",
    "         <li> data[1] corresponde a 10 Tensors que contém o label de cada imagem(diz se é 1, 2, 3 etc) </li>\n",
    "         <li> data[0][0] corresponde à primeira imagem de entrada do batch </li>\n",
    "         <li> data[1][0] corresponde ao primeiro label do batch</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1255, 0.8549,\n",
      "          1.0000, 0.9725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.8392, 0.9922,\n",
      "          0.9922, 0.4706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8902, 0.9922, 0.9922,\n",
      "          0.9922, 0.9020, 0.8353, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8902, 0.9922, 0.9529,\n",
      "          0.5059, 0.9922, 0.9922, 0.4627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.6118, 0.5490,\n",
      "          0.0353, 0.7020, 0.9922, 0.5882, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5373, 0.9922, 0.6078, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0275, 0.9922, 0.9922, 0.1333, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0275, 0.9922, 0.9922, 0.1333, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5098, 0.9922, 0.8510, 0.0863, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.9137, 0.9922, 0.5882, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1059, 0.0000, 0.0000,\n",
      "          0.2118, 0.9922, 0.9922, 0.5882, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.3373, 0.6471, 0.8353, 0.1804, 0.0235,\n",
      "          0.6824, 0.9922, 0.9412, 0.2353, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0078, 0.1020, 0.5647, 0.7608, 0.9647, 0.9882, 0.8784, 0.6471,\n",
      "          0.9922, 0.9765, 0.2196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.4824, 0.9922, 0.9373, 0.0000, 0.0000, 0.8902, 0.9922, 0.9922,\n",
      "          0.9922, 0.7020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2863,\n",
      "          0.9804, 0.9373, 0.2667, 0.0000, 0.0000, 0.8902, 0.9922, 0.9922,\n",
      "          0.9922, 0.6471, 0.0000, 0.0000, 0.0000, 0.3216, 0.4078, 0.6627,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1255, 0.8157,\n",
      "          0.9922, 0.6824, 0.0000, 0.1686, 0.8510, 0.9804, 0.9922, 0.9922,\n",
      "          0.9922, 0.9882, 0.6000, 0.3255, 0.3255, 0.8510, 0.8510, 0.1216,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8039, 0.9922,\n",
      "          0.6902, 0.2353, 0.2745, 0.8902, 0.9922, 0.9059, 0.6039, 0.3137,\n",
      "          0.9098, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.6980, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.9686, 0.9922,\n",
      "          0.7686, 0.8980, 0.9922, 0.9098, 0.5961, 0.1922, 0.0000, 0.0000,\n",
      "          0.2510, 0.8353, 0.9922, 0.9255, 0.8314, 0.4078, 0.0863, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4627, 0.9922, 0.9922,\n",
      "          0.9922, 0.9804, 0.8824, 0.1843, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0118, 0.3765, 0.2235, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4627, 0.9922, 0.9922,\n",
      "          0.9922, 0.5647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "y:  tensor(2)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "\n",
    "print(\"x: \", x)\n",
    "print(\"y: \", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos visualizar se as features e labels estão com os índices pareados corretamente.\n",
    "\n",
    "Antes de poder printar no matplotlib, devemos fazer um reshape(view) para o formato (28, 28), pois o formato atual é (1, 28, 28). Esse 1 é referente à quantidade de canais da imagem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5515a2b2b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0][0].view(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanceamento\n",
    "\n",
    "Um fator bastante importante é verificar se o dataset está balanceado. Vamos supor que 80% dos elementos dele sejam imagens de números 2. Isso causaria sérios problemas de generalização no dataset. \n",
    "\n",
    "Vamos checar se nosso dataset está balanceado. Para isso, criaremos um dicionário que irá guardar a quantidade de cada label que possuímos no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    xs, ys = data\n",
    "    for y in ys:\n",
    "       counter_dict[int(y)] += 1 \n",
    "    \n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, os labels estão balanceados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
